<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="/styling/scripts.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<link rel="stylesheet" type="text/css" href="/styling/styles.css">
<script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  jax: ['input/TeX', 'output/HTML-CSS'],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    extensions: ['color.js']
  },
  messageStyle: 'none',
  'HTML-CSS': { preferredFont: 'TeX', availableFonts: ['STIX','TeX'] }
});
</script>

<script src='//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML' type='text/javascript'></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<!--KaTeX-->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
              // ...options...
        });
    });
</script>

<!--<meta charset="utf-8">
<title>journals</title>-->
</head>
<body>

<div class="navbar">
<div class="mode_button"><i onclick="myDark(this)" class="fa fa-moon-o"></i></div>
<div class="navbar_txt"><a href="/">Aniket Pramanik</a></div>
<div class="navdrop">
  <div class="nav">
  <div></div>
  <div></div>
  <div></div>
  </div>
  <!--<div class="navdrop-content">
    <a href="index.html">About</a>
    <a href="experience.html">Experience</a>
    <a href="pub_ns.html">Publications</a>
    <a href="blog_list.html">Blog</a>
  </div>-->
  <div class="navdrop-content">
    <a href="/">About</a>
    <a href="/experience.html">Experience</a>
    <a href="/pub_index.html">Publications</a>
    <a href="/blog_list.html">Blog</a>
  </div>
</div>
</div>

<script>
var element = document.body;
if(localStorage.getItem("mode") == "dark") {
       element.className = "dark-mode";
       element.getElementsByTagName("i")[0].className = "fa fa-sun-o";
  }
else{
element.className = "";
element.getElementsByTagName("i")[0].className = "fa fa-moon-o";
}
</script>




<div class="intro">

<h1 style="margin-top: 20%; margin-bottom: 7%; line-height: 20px">Publications</h1>

<span style="margin-top: 10%; margin-bottom: 10%">Please see my <a href="https://scholar.google.com/citations?user=8z5UYtoAAAAJ&hl=en">Google Scholar</a> for a full list of publications.</span>



<div style="margin-top: 3%; margin-bottom: 3%;">


<button onclick="location.href='/pub_index.html'" type="button", class="dropbtn">All</button>
<button onclick="location.href='/articles/journal.html'" type="button", class="dropbtn">Journals</button>
<button onclick="location.href='/articles/conference.html'" type="button", class="pub_button">Conferences</button>
<button onclick="location.href='/articles/wab.html'" type="button", class="pub_button">Workshops and Abstracts</button>


</div>


</div>





<div class="intro">
<hr style="margin-top: 10%; border-top: 1px dashed black;">

<h2 style="margin-top: 3%; margin-bottom: 3%; line-height: 20px">Journals</h2>


<table class="pub">







<tr>
  <td><div class="journal_box"><b>arXiv</b></div></td>
  <td><div class="journal_details">Stable and Memory-Efficient Image Recovery Using Monotone Operator Learning</div>

  




    

      

        
          <div class="me">Aniket Pramanik</div>,

        

      


    

      

        
          <a class="advisor" href="https://engineering.uiowa.edu/people/mathews-jacob">Mathews Jacob</a>.

        

      


    



  <br>
  <i>arXiv</i>
  <br>
  <button onclick="myFunction('We introduce a monotone deep equilibrium learning framework for large-scale inverse problems in imaging. The proposed algorithm relies on forward-backward splitting, where each iteration consists of a gradient descent involving the score function and a conjugate gradient algorithm to encourage data consistency. The score function is modeled as a monotone convolutional neural network. The use of a monotone operator offers several benefits, including guaranteed convergence, uniqueness of fixed point, and robustness to input perturbations, similar to the use of convex priors in compressive sensing. In addition, the proposed formulation is significantly more memory-efficient than unrolled methods, which allows us to apply it to 3D problems that current unrolled algorithms cannot handle. Experiments show that the proposed scheme can offer improved performance in 3D settings while being stable in the presence of input perturbations.')" type="button", class="dropbtn">Abstract</button>
  <button onclick="myFunction('@article{pramanik2022stable, <br> title={Stable and memory-efficient image recovery using monotone operator learning (MOL)}, <br> author={Pramanik, Aniket and Jacob, Mathews}, <br> journal={arXiv preprint arXiv:2206.04797}, <br> year={2022} <br> }')" type="button", class="dropbtn">BiB</button>
  <button onclick="location.href='https://arxiv.org/abs/2206.04797'" type="button", class="pub_button">Arxiv</button>

  
  

  

  



  <div  id='We introduce a monotone deep equilibrium learning framework for large-scale inverse problems in imaging. The proposed algorithm relies on forward-backward splitting, where each iteration consists of a gradient descent involving the score function and a conjugate gradient algorithm to encourage data consistency. The score function is modeled as a monotone convolutional neural network. The use of a monotone operator offers several benefits, including guaranteed convergence, uniqueness of fixed point, and robustness to input perturbations, similar to the use of convex priors in compressive sensing. In addition, the proposed formulation is significantly more memory-efficient than unrolled methods, which allows us to apply it to 3D problems that current unrolled algorithms cannot handle. Experiments show that the proposed scheme can offer improved performance in 3D settings while being stable in the presence of input perturbations.'  class="dropdown-content-abstract">
  We introduce a monotone deep equilibrium learning framework for large-scale inverse problems in imaging. The proposed algorithm relies on forward-backward splitting, where each iteration consists of a gradient descent involving the score function and a conjugate gradient algorithm to encourage data consistency. The score function is modeled as a monotone convolutional neural network. The use of a monotone operator offers several benefits, including guaranteed convergence, uniqueness of fixed point, and robustness to input perturbations, similar to the use of convex priors in compressive sensing. In addition, the proposed formulation is significantly more memory-efficient than unrolled methods, which allows us to apply it to 3D problems that current unrolled algorithms cannot handle. Experiments show that the proposed scheme can offer improved performance in 3D settings while being stable in the presence of input perturbations.
  </div>

  <div id='@article{pramanik2022stable, <br> title={Stable and memory-efficient image recovery using monotone operator learning (MOL)}, <br> author={Pramanik, Aniket and Jacob, Mathews}, <br> journal={arXiv preprint arXiv:2206.04797}, <br> year={2022} <br> }' class="dropdown-content-abstract">
  @article{pramanik2022stable, <br> title={Stable and memory-efficient image recovery using monotone operator learning (MOL)}, <br> author={Pramanik, Aniket and Jacob, Mathews}, <br> journal={arXiv preprint arXiv:2206.04797}, <br> year={2022} <br> }
  </div>

   </td>
  </tr>



<tr>
  <td><div class="journal_box"><b>TMI</b></div></td>
  <td><div class="journal_details">ENSURE: A General Approach for Unsupervised Training of Deep Image Reconstruction Algorithms</div>

  




    

      

        
          Hemant Aggarwal,

        

      


    

      

        
          <div class="me">Aniket Pramanik</div>,

        

      


    

      

        
          <a class="advisor" href="https://engineering.uiowa.edu/people/mathews-jacob">Mathews Jacob</a>.

        

      


    



  <br>
  <i>IEEE Transactions on Medical Imaging</i>
  <br>
  <button onclick="myFunction('Image reconstruction using deep learning algorithms offers improved reconstruction quality and lower reconstruction time than classical compressed sensing and model-based algorithms. Unfortunately, clean and fully sampled ground-truth data to train the deep networks is often not available in several applications, restricting the applicability of the above methods. This work introduces the ENsemble Stein's Unbiased Risk Estimate (ENSURE) framework as a general approach to train deep image reconstruction algorithms without fully sampled and noise-free images. The proposed framework is the generalization of the classical SURE and GSURE formulation to the setting where the images are sampled by different measurement operators, chosen randomly from a set. We show that the ENSURE loss function, which only uses the measurement data, is an unbiased estimate for the true mean-square error. Our experiments show that the networks trained with this loss function can offer reconstructions comparable to the supervised setting. While we demonstrate this framework in the context of MR image recovery, the ENSURE framework is generally applicable to arbitrary inverse problems.')" type="button", class="dropbtn">Abstract</button>
  <button onclick="myFunction('@article{aggarwal2020ensure, <br> title={ENSURE: A General Approach for Unsupervised Training of Deep Image Reconstruction Algorithms}, <br> author={Aggarwal, Hemant Kumar and Pramanik, Aniket and Jacob, Mathews}, <br> journal={arXiv preprint arXiv:2010.10631}, <br> year={2020} <br> }')" type="button", class="dropbtn">BiB</button>
  <button onclick="location.href='https://arxiv.org/abs/2010.10631'" type="button", class="pub_button">Arxiv</button>

  
  

  

  



  <div  id='Image reconstruction using deep learning algorithms offers improved reconstruction quality and lower reconstruction time than classical compressed sensing and model-based algorithms. Unfortunately, clean and fully sampled ground-truth data to train the deep networks is often not available in several applications, restricting the applicability of the above methods. This work introduces the ENsemble Stein's Unbiased Risk Estimate (ENSURE) framework as a general approach to train deep image reconstruction algorithms without fully sampled and noise-free images. The proposed framework is the generalization of the classical SURE and GSURE formulation to the setting where the images are sampled by different measurement operators, chosen randomly from a set. We show that the ENSURE loss function, which only uses the measurement data, is an unbiased estimate for the true mean-square error. Our experiments show that the networks trained with this loss function can offer reconstructions comparable to the supervised setting. While we demonstrate this framework in the context of MR image recovery, the ENSURE framework is generally applicable to arbitrary inverse problems.'  class="dropdown-content-abstract">
  Image reconstruction using deep learning algorithms offers improved reconstruction quality and lower reconstruction time than classical compressed sensing and model-based algorithms. Unfortunately, clean and fully sampled ground-truth data to train the deep networks is often not available in several applications, restricting the applicability of the above methods. This work introduces the ENsemble Stein's Unbiased Risk Estimate (ENSURE) framework as a general approach to train deep image reconstruction algorithms without fully sampled and noise-free images. The proposed framework is the generalization of the classical SURE and GSURE formulation to the setting where the images are sampled by different measurement operators, chosen randomly from a set. We show that the ENSURE loss function, which only uses the measurement data, is an unbiased estimate for the true mean-square error. Our experiments show that the networks trained with this loss function can offer reconstructions comparable to the supervised setting. While we demonstrate this framework in the context of MR image recovery, the ENSURE framework is generally applicable to arbitrary inverse problems.
  </div>

  <div id='@article{aggarwal2020ensure, <br> title={ENSURE: A General Approach for Unsupervised Training of Deep Image Reconstruction Algorithms}, <br> author={Aggarwal, Hemant Kumar and Pramanik, Aniket and Jacob, Mathews}, <br> journal={arXiv preprint arXiv:2010.10631}, <br> year={2020} <br> }' class="dropdown-content-abstract">
  @article{aggarwal2020ensure, <br> title={ENSURE: A General Approach for Unsupervised Training of Deep Image Reconstruction Algorithms}, <br> author={Aggarwal, Hemant Kumar and Pramanik, Aniket and Jacob, Mathews}, <br> journal={arXiv preprint arXiv:2010.10631}, <br> year={2020} <br> }
  </div>

   </td>
  </tr>



<tr>
  <td><div class="journal_box"><b>TMI</b></div></td>
  <td><div class="journal_details">Deep Generalization of Structured Low-Rank Algorithms (Deep-SLR)</div>

  




    

      

        
          <div class="me">Aniket Pramanik</div>,

        

      


    

      

        
          Hemant Aggarwal,

        

      


    

      

        
          <a class="advisor" href="https://engineering.uiowa.edu/people/mathews-jacob">Mathews Jacob</a>.

        

      


    



  <br>
  <i>IEEE Transactions on Medical Imaging</i>
  <br>
  <button onclick="myFunction('Structured low-rank (SLR) algorithms, which exploit annihilation relations between the Fourier samples of a signal resulting from different properties, is a powerful image reconstruction framework in several applications. This scheme relies on low-rank matrix completion to estimate the annihilation relations from the measurements. The main challenge with this strategy is the high computational complexity of matrix completion. We introduce a deep learning (DL) approach to significantly reduce the computational complexity. Specifically, we use a convolutional neural network (CNN)-based filterbank that is trained to estimate the annihilation relations from imperfect (under-sampled and noisy) k-space measurements of Magnetic Resonance Imaging (MRI). The main reason for the computational efficiency is the pre-learning of the parameters of the non-linear CNN from exemplar data, compared to SLR schemes that learn the linear filterbank parameters from the dataset itself. Experimental comparisons show that the proposed scheme can enable calibration-less parallel MRI; it can offer performance similar to SLR schemes while reducing the runtime by around three orders of magnitude. Unlike pre-calibrated and self-calibrated approaches, the proposed uncalibrated approach is insensitive to motion errors and affords higher acceleration. The proposed scheme also incorporates image domain priors that are complementary, thus significantly improving the performance over that of SLR schemes.')" type="button", class="dropbtn">Abstract</button>
  <button onclick="myFunction('@article{pramanik2020deep, <br> title={Deep generalization of structured low-rank algorithms (Deep-SLR)}, <br> author={Pramanik, Aniket and Aggarwal, Hemant Kumar and Jacob, Mathews}, <br> journal={IEEE transactions on medical imaging}, <br> volume={39}, <br> number={12}, <br> pages={4186--4197}, <br> year={2020}, <br> publisher={IEEE} <br> }')" type="button", class="dropbtn">BiB</button>
  <button onclick="location.href='https://arxiv.org/abs/1912.03433'" type="button", class="pub_button">Arxiv</button>

  
  

  

  
    <button onclick="location.href='code'" type="button", class="pub_button">Code</button>
  



  <div  id='Structured low-rank (SLR) algorithms, which exploit annihilation relations between the Fourier samples of a signal resulting from different properties, is a powerful image reconstruction framework in several applications. This scheme relies on low-rank matrix completion to estimate the annihilation relations from the measurements. The main challenge with this strategy is the high computational complexity of matrix completion. We introduce a deep learning (DL) approach to significantly reduce the computational complexity. Specifically, we use a convolutional neural network (CNN)-based filterbank that is trained to estimate the annihilation relations from imperfect (under-sampled and noisy) k-space measurements of Magnetic Resonance Imaging (MRI). The main reason for the computational efficiency is the pre-learning of the parameters of the non-linear CNN from exemplar data, compared to SLR schemes that learn the linear filterbank parameters from the dataset itself. Experimental comparisons show that the proposed scheme can enable calibration-less parallel MRI; it can offer performance similar to SLR schemes while reducing the runtime by around three orders of magnitude. Unlike pre-calibrated and self-calibrated approaches, the proposed uncalibrated approach is insensitive to motion errors and affords higher acceleration. The proposed scheme also incorporates image domain priors that are complementary, thus significantly improving the performance over that of SLR schemes.'  class="dropdown-content-abstract">
  Structured low-rank (SLR) algorithms, which exploit annihilation relations between the Fourier samples of a signal resulting from different properties, is a powerful image reconstruction framework in several applications. This scheme relies on low-rank matrix completion to estimate the annihilation relations from the measurements. The main challenge with this strategy is the high computational complexity of matrix completion. We introduce a deep learning (DL) approach to significantly reduce the computational complexity. Specifically, we use a convolutional neural network (CNN)-based filterbank that is trained to estimate the annihilation relations from imperfect (under-sampled and noisy) k-space measurements of Magnetic Resonance Imaging (MRI). The main reason for the computational efficiency is the pre-learning of the parameters of the non-linear CNN from exemplar data, compared to SLR schemes that learn the linear filterbank parameters from the dataset itself. Experimental comparisons show that the proposed scheme can enable calibration-less parallel MRI; it can offer performance similar to SLR schemes while reducing the runtime by around three orders of magnitude. Unlike pre-calibrated and self-calibrated approaches, the proposed uncalibrated approach is insensitive to motion errors and affords higher acceleration. The proposed scheme also incorporates image domain priors that are complementary, thus significantly improving the performance over that of SLR schemes.
  </div>

  <div id='@article{pramanik2020deep, <br> title={Deep generalization of structured low-rank algorithms (Deep-SLR)}, <br> author={Pramanik, Aniket and Aggarwal, Hemant Kumar and Jacob, Mathews}, <br> journal={IEEE transactions on medical imaging}, <br> volume={39}, <br> number={12}, <br> pages={4186--4197}, <br> year={2020}, <br> publisher={IEEE} <br> }' class="dropdown-content-abstract">
  @article{pramanik2020deep, <br> title={Deep generalization of structured low-rank algorithms (Deep-SLR)}, <br> author={Pramanik, Aniket and Aggarwal, Hemant Kumar and Jacob, Mathews}, <br> journal={IEEE transactions on medical imaging}, <br> volume={39}, <br> number={12}, <br> pages={4186--4197}, <br> year={2020}, <br> publisher={IEEE} <br> }
  </div>

   </td>
  </tr>



</table>

</div>





</body>
</html>
